{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Integrate Dataset\n",
        "\n",
        "---\n",
        "\n",
        "Given a time-correlated dataset, do the following:\n",
        "* visualize\n",
        "* expose and deal with missing data\n",
        "* create a date column as a merge point\n",
        "* merge w/ given aggregate dataset\n",
        "\n",
        "\n",
        "Requires:\n",
        "* Project_Util"
      ],
      "metadata": {
        "id": "MDnCzDVoM0ZE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from datetime import datetime as dt\n",
        "import datetime\n",
        "\n",
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns; sns.set()\n",
        "plt.rcParams[\"figure.figsize\"] = (10,6)\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "plt.style.use('seaborn')\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "WWu_MYu0lkNC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def merge_co2_dataset(data_path, df_aggr, start_date, end_date, feature_map, impute_method='bfill', DATE_COL='date'):\n",
        "  \"\"\"\n",
        "  Load data from the given data_path.\n",
        "  Locate the date column and re-code as a pd.timestamp.\n",
        "  Merge into given df_aggr.\n",
        "  \"\"\"\n",
        "  print(f'### Loading data{data_path}::')\n",
        "  df = pd.read_csv(data_path)\n",
        "\n",
        "  df.describe().T\n",
        "\n",
        "  df.info()\n",
        "  df.tail(3)\n",
        "\n",
        "  # set types\n",
        "  df['Year'] = df['Year'].astype(dtype='int32')\n",
        "  df['Month'] = df['Month'].astype(dtype='int32')\n",
        "\n",
        "  df[DATE_COL] = df.apply(lambda x: pd.to_datetime(f'{int(x.Month):02}/01/{int(x.Year)}'), axis=1)\n",
        "\n",
        "  # Truncate by date\n",
        "  df = df[df[DATE_COL] >= start_date]\n",
        "  df = df[df[DATE_COL] <= end_date]\n",
        "\n",
        "  # Rename columns\n",
        "  df.rename(columns=feature_map, inplace=True)\n",
        "\n",
        "  # Grab real column names\n",
        "  COLS = []\n",
        "  for col in feature_map.values():\n",
        "    COLS.append(col)\n",
        "\n",
        "  # Handle missing values\n",
        "  for col in COLS:\n",
        "    df[col].fillna(method=impute_method, inplace=True)\n",
        "\n",
        "  plt.rcParams[\"figure.figsize\"] = [8,6]\n",
        "  plt.plot(df['date'], df[COLS])\n",
        "  plt.xlabel('Date')\n",
        "  plt.ylabel('CO2 (ppm)')\n",
        "  plt.title('CO2 over Time')\n",
        "  plt.legend(COLS)\n",
        "  plt.show()\n",
        "\n",
        "  # Check time intervals\n",
        "  df['interval'] = df.date - df.date.shift(1)\n",
        "  df[['date', 'interval']].head()\n",
        "  print(\"------ Interval Counts - should be on the month ------\")\n",
        "  print(f\"{df['interval'].value_counts()}\")\n",
        "  df.drop(columns=['interval'], inplace=True)\n",
        "\n",
        "\n",
        "  # Drop other unnecessasry columns\n",
        "  COLS.append(DATE_COL)\n",
        "  df = df_retain(df, COLS)\n",
        "  df.head()\n",
        "\n",
        "  # Merge dataset\n",
        "  return pd.merge(df_aggr, df, on=DATE_COL, how='inner')"
      ],
      "metadata": {
        "id": "HjMLJtjiQJZs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d = {}\n",
        "d['k1'] = 'val1'\n",
        "d['k2'] = 22\n"
      ],
      "metadata": {
        "id": "cFa44PwcSB7i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "--Xazpo9sqfa"
      },
      "outputs": [],
      "source": [
        "if False:\n",
        "  debug = True\n",
        "\n",
        "  DRIVE_PATH = \"/content/drive/MyDrive/data606\"\n",
        "\n",
        "  # Set the location of this script in GDrive\n",
        "  SCRIPT_PATH = DRIVE_PATH + \"/src/\"\n",
        "\n",
        "  # Root Path of the data on the cloud drive\n",
        "  DATA_ROOT = DRIVE_PATH + \"/data/\"\n",
        "  data_path = DATA_ROOT + \"atmospheric-co2.csv\"\n",
        "\n",
        "  # Start including data from this date\n",
        "  start_date =  pd.to_datetime(dt.fromisoformat('1950-01-01'))\n",
        "  # Stop including data after this date\n",
        "  end_date = pd.to_datetime(dt.fromisoformat('2022-12-31'))\n",
        "\n",
        "  features = ['Seasonally Adjusted CO2 Fit (ppm)']\n",
        "\n",
        "  # Mount drive\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "\n",
        "  %cd $SCRIPT_PATH\n",
        "\n",
        "  # Load util class\n",
        "  %run -i \"./ProjectUtil.ipynb\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SmXQSFSWJV1O"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Integrate Generic Dataset\n",
        "\n",
        "---\n",
        "\n",
        "Given a time-correlated dataset, do the following:\n",
        "* visualize\n",
        "* expose and deal with missing data\n",
        "* create a date column as a merge point\n",
        "* merge w/ given aggregate dataset\n",
        "\n",
        "\n",
        "Requires:\n",
        "* Project_Util"
      ],
      "metadata": {
        "id": "MDnCzDVoM0ZE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from datetime import datetime as dt\n",
        "import datetime\n",
        "\n",
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns; sns.set()\n",
        "plt.rcParams[\"figure.figsize\"] = (10,6)\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "plt.style.use('seaborn')\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "WWu_MYu0lkNC"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def merge_dataset(data_path, df_aggr, start_date, end_date, feature_map, impute_method='bfill', date_map=None, date_col=None):\n",
        "  \"\"\"\n",
        "  Load data from the given data_path.\n",
        "  Date bounds.\n",
        "  If date_col is set, will use this to create dates.\n",
        "  Otherwise supply a  date_map, mapping columns to 'year','month', and 'day'.\n",
        "  Re-code 'date' as a pd.timestamp.\n",
        "  Merge into given df_aggr.\n",
        "  \"\"\"\n",
        "  print(f'### Loading data{data_path}::')\n",
        "  df = pd.read_csv(data_path)\n",
        "\n",
        "  # This is the common merge date field name\n",
        "  DATE_COL='date'\n",
        "\n",
        "  # Grab real column names\n",
        "  COLS = []\n",
        "  for col in feature_map.values():\n",
        "    COLS.append(col)\n",
        "\n",
        "  # GUARD\n",
        "  if (len(COLS) <= 0):\n",
        "    raise AssertionError(f'{data_path} - Provide at least one feature_map entry')\n",
        "\n",
        "  # Rename columns\n",
        "  df.rename(columns=feature_map, inplace=True)\n",
        "  if (date_map is not None):\n",
        "    df.rename(columns=date_map, inplace=True)\n",
        "\n",
        "  # Handle missing values\n",
        "  for col in COLS:\n",
        "    df[col].fillna(method=impute_method, inplace=True)\n",
        "\n",
        "  df.info()\n",
        "\n",
        "  print('isna() value counts::')\n",
        "  #df.isna().value_counts()\n",
        "\n",
        "  # Standardize dates\n",
        "  if (date_col is None):\n",
        "    # Create a date format string\n",
        "    datestr = []\n",
        "    if ('day' in df.columns):\n",
        "      # Recode as a formatted string\n",
        "      df['day'] = df['day'].astype(dtype='int32')\n",
        "      df['days'] = df['day'].apply(lambda x: f'{x:02}')\n",
        "      datestr.append('{days}/')\n",
        "    else:\n",
        "      datestr.append('01/')\n",
        "\n",
        "    if ('month' in df.columns):\n",
        "      # Recode as a formatted string\n",
        "      df['month'] = df['month'].astype(dtype='int32')\n",
        "      df['months'] = df['month'].apply(lambda x: f'{x:02}')\n",
        "      #print(f'month has nans:: {df.month.hasnans()}')\n",
        "      datestr.append('{months}/')\n",
        "    else:\n",
        "      datestr.append('01/')\n",
        "\n",
        "    # Recode as a formatted string\n",
        "    df['year'] = df['year'].astype(dtype='int32')\n",
        "    df['years'] = df['year'].apply(lambda x: f'{x:4}')\n",
        "    datestr.append('{years}')\n",
        "    # Finalize format string\n",
        "    datestr = \"\".join(datestr)\n",
        "\n",
        "    print(f'Using date format: {datestr}')\n",
        "    date_col = 'dt'\n",
        "    df[date_col] = df.apply(lambda x: pd.to_datetime(datestr.format_map(x)), axis=1)\n",
        "\n",
        "  print('Doing date conversion ------')\n",
        "  # NOW - convert date to pd.Timestamp\n",
        "  df[DATE_COL] = pd.to_datetime(df[date_col])\n",
        "\n",
        "  # Now we can...Truncate by date\n",
        "  df = df[df[DATE_COL] >= start_date]\n",
        "  df = df[df[DATE_COL] <= end_date]\n",
        "\n",
        "  plt.rcParams[\"figure.figsize\"] = [8,6]\n",
        "  plt.plot(df[DATE_COL], df[COLS])\n",
        "  plt.xlabel('Date')\n",
        "  plt.ylabel('CO2 (ppm)')\n",
        "  plt.title('CO2 over Time')\n",
        "  plt.legend(COLS)\n",
        "  plt.show()\n",
        "\n",
        "  # Check time intervals\n",
        "  df['interval'] = df.date - df.date.shift(1)\n",
        "  df[[DATE_COL, 'interval']].head()\n",
        "  print(\"------ Interval Counts - should be on the month ------\")\n",
        "  print(f\"{df['interval'].value_counts()}\")\n",
        "  df.drop(columns=['interval'], inplace=True)\n",
        "\n",
        "  # Drop other unnecessasry columns\n",
        "  COLS.append(DATE_COL)\n",
        "  df = df_retain(df, COLS)\n",
        "\n",
        "  df.info()\n",
        "  print('Merging by date ------')\n",
        "\n",
        "  # Merge dataset\n",
        "  return pd.merge(df_aggr, df, on=DATE_COL, how='inner')"
      ],
      "metadata": {
        "id": "HjMLJtjiQJZs"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "--Xazpo9sqfa"
      },
      "outputs": [],
      "source": [
        "if False:\n",
        "  debug = True\n",
        "\n",
        "  DRIVE_PATH = \"/content/drive/MyDrive/data606\"\n",
        "\n",
        "  # Set the location of this script in GDrive\n",
        "  SCRIPT_PATH = DRIVE_PATH + \"/src/\"\n",
        "\n",
        "  # Root Path of the data on the cloud drive\n",
        "  DATA_ROOT = DRIVE_PATH + \"/data/\"\n",
        "  data_path = DATA_ROOT + \"atmospheric-co2.csv\"\n",
        "\n",
        "  # Start including data from this date\n",
        "  start_date =  pd.to_datetime(dt.fromisoformat('1950-01-01'))\n",
        "  # Stop including data after this date\n",
        "  end_date = pd.to_datetime(dt.fromisoformat('2022-12-31'))\n",
        "\n",
        "  features = ['Seasonally Adjusted CO2 Fit (ppm)']\n",
        "\n",
        "  # Mount drive\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "\n",
        "  %cd $SCRIPT_PATH\n",
        "\n",
        "  # Load util class\n",
        "  %run -i \"./ProjectUtil.ipynb\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SmXQSFSWJV1O"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
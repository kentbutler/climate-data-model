{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1MzbV7PHprt9jzcoEHRImpenF9dcjuIlG","timestamp":1695179598808}],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["---\n","\n","## LSTM Model v1\n","\n","---\n","\n","Basic usage of an LSTM - single variable."],"metadata":{"id":"MDnCzDVoM0ZE"}},{"cell_type":"code","source":["import math\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.metrics import mean_squared_error\n","from keras.layers import Dense,RepeatVector, LSTM, Dropout\n","from keras.layers import Flatten, Conv1D, MaxPooling1D\n","from keras.layers import Bidirectional, Dropout\n","from keras.models import Sequential\n","from keras.utils import plot_model"],"metadata":{"id":"8nFjo6OMngaT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class ModelLSTMv1:\n","  \"\"\"\n","  Constructs a model instance. Input data should be a dataframe containing\n","  only the data to be modeled.\n","  \"\"\"\n","  debug = False\n","\n","  def __init__(self, input, window_size=30, scale_range=(-1,1), test_ratio=0.2, num_epochs=300, debug=False):\n","    self.debug = debug\n","\n","    # GUARDs\n","    if input is None:\n","      raise ValueError ('ModelLSTMv1 requires input')\n","\n","    if self.debug:\n","      print('### Building ModelLSTMv1::')\n","\n","    self.input = input\n","    self.WINDOW_SIZE = window_size\n","    self.SCALE_RANGE = scale_range\n","    self.TEST_RATIO = test_ratio\n","    self.NUM_EPOCHS = num_epochs\n","\n","\n","  def prep(self):\n","    \"\"\"\n","    Performs scaling of the data\n","    \"\"\"\n","    # Create transformed input data by scaling\n","    self.scaler = MinMaxScaler(feature_range=self.SCALE_RANGE)\n","    input_tx = self.scaler.fit_transform(self.input)\n","\n","    if self.debug:\n","      print(f'### After scaling data type is: {type(input_tx)}')\n","\n","    # Now create X and y modeling vars\n","    X = []\n","    y = []\n","\n","    # Move window through training data - each block of input X has a single supervised target y\n","    for i in range(len(input_tx) - self.WINDOW_SIZE):\n","        X.append(input_tx[i:i+self.WINDOW_SIZE])\n","        y.append(input_tx[i+self.WINDOW_SIZE])\n","\n","    # convert to np arrays\n","    X = np.asanyarray(X)\n","    y = np.asanyarray(y)\n","\n","    # Split into train/test\n","    NUM_TEST = math.floor(len(input_tx) * self.TEST_RATIO)\n","    NUM_TRAIN = len(input_tx) - NUM_TEST\n","\n","    self.X_train = X[:NUM_TRAIN,:,:]\n","    self.X_test = X[NUM_TRAIN:,:,:]\n","    self.y_train = y[:NUM_TRAIN]\n","    self.y_test= y[NUM_TRAIN:]\n","\n","    if self.debug:\n","      print(f'X_train, y_train: {self.X_train.shape}, {self.y_train.shape}')\n","\n","  def train(self):\n","    \"\"\"\n","    Declare model and train.\n","    Based on https://keras.io/examples/timeseries/timeseries_classification_from_scratch/.\n","    \"\"\"\n","    from keras.callbacks import ModelCheckpoint, TensorBoard, Callback, EarlyStopping\n","    early_stop = EarlyStopping(monitor = \"loss\", mode = \"min\", patience = 7)\n","    model = Sequential()\n","    model.add(Conv1D(filters=256, kernel_size=2, activation='relu', input_shape=(30,1)))\n","    model.add(Conv1D(filters=128, kernel_size=2, activation='relu'))\n","    model.add(MaxPooling1D(pool_size=2))\n","    model.add(Flatten())\n","    model.add(RepeatVector(30))\n","    model.add(LSTM(units=100, return_sequences=True, activation='relu'))\n","    model.add(Dropout(0.2))\n","    model.add(LSTM(units=100, return_sequences=True, activation='relu'))\n","    model.add(Dropout(0.2))\n","    model.add(LSTM(units=100, return_sequences=True, activation='relu'))\n","    model.add(LSTM(units=100, return_sequences=True, activation='relu'))\n","    model.add(Bidirectional(LSTM(128, activation='relu')))\n","    model.add(Dense(100, activation='relu'))\n","    model.add(Dense(1))\n","    model.compile(loss='mse', optimizer='adam')\n","\n","    self.model_hist = model.fit(self.X_train, self.y_train, epochs=self.NUM_EPOCHS, verbose=1, callbacks = [early_stop] )\n","    self.model = model\n","\n","  def get_model_name(self):\n","    from datetime import datetime\n","    return f\"{datetime.today().strftime('%Y%m%d-%H%M')}-LSTMv1.hdf5\"\n","\n","  def save_model(self, path):\n","    \"\"\"\n","    Save the current model under the given drive path.\n","    Timestamp the model name.\n","    \"\"\"\n","    fname = f'{path}{self.get_model_name()}'\n","    if self.debug:\n","      print(f'Saving model to: {fname}')\n","    return self.model.save(fname)\n","\n","  def predict(self):\n","    pred = self.model.predict(self.X_test)\n","\n","    y_test = self.scaler.inverse_transform(self.y_test)\n","\n","    plt.figure(figsize=(20,9))\n","    plt.plot(y_test , 'blue', linewidth=5)\n","    plt.plot(pred,'r' , linewidth=4)\n","    plt.legend(('Test','Predicted'))\n","    plt.show()\n","\n","    print(f'MSE: {mean_squared_error(y_test, pred)}')"],"metadata":{"id":"HjMLJtjiQJZs"},"execution_count":null,"outputs":[]}]}
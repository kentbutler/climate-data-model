{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from pandas.tseries.offsets import Day, MonthBegin, YearBegin"
      ],
      "metadata": {
        "id": "ps_zC2UvT_yi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KPEDYz5jTiKl"
      },
      "outputs": [],
      "source": [
        "def get_df_types(df, debug=False):\n",
        "  # Create lists of column names by data type\n",
        "  floats=[]\n",
        "  ints=[]\n",
        "  strings=[]\n",
        "  other=[]\n",
        "\n",
        "  for col in df.columns:\n",
        "    if debug:\n",
        "      print(f'## {col}:\\t\\t{df[col].dtype}')\n",
        "    t = df[col].dtype.name\n",
        "    if t.find('float') >= 0:\n",
        "      floats.append(col)\n",
        "    elif t.find('int') >= 0:\n",
        "      ints.append(col)\n",
        "    elif t.find('object') >= 0:\n",
        "      strings.append(col)\n",
        "    else:\n",
        "      other.append(col)\n",
        "\n",
        "  if debug:\n",
        "    print(f'Types::\\n\\tInts: {ints}'),print(f'\\tFloats: {floats}'),print(f'\\tStrings: {strings}'),print(f'\\tOther: {other}')\n",
        "\n",
        "  return floats,ints,strings,other\n",
        "\n",
        "\n",
        "def df_to_arrays(df, target_label, debug=False):\n",
        "  \"\"\"\n",
        "  Given a DataFrame, convert into a 2D array of numerics.\n",
        "  Target variable is returned as y.\n",
        "\n",
        "  Returns a 2D ndarray as X, ndarray as y, and optional encoder for y\n",
        "  if encoding was necessary.\n",
        "  \"\"\"\n",
        "  target_encoder = None\n",
        "  X = []\n",
        "  y = []\n",
        "\n",
        "  # Numericize non-numerics\n",
        "  for alpha_col in alphas:\n",
        "    if debug:\n",
        "      print(f'Label encoding col: {alpha_col}')\n",
        "    label_enc = LabelEncoder()\n",
        "    enc_col = label_enc.fit_transform(df[alpha_col].values)\n",
        "    if alpha_col == target_label:\n",
        "      target_encoder = label_enc\n",
        "      y.append(enc_col)\n",
        "    else:\n",
        "      X.append(enc_col)\n",
        "\n",
        "  for numeric_col in numerics:\n",
        "    if numeric_col == target_label:\n",
        "      y.append(df[numeric_col].values)\n",
        "    else:\n",
        "      X.append(df[numeric_col].values)\n",
        "\n",
        "  return np.array(X), np.array(y), target_encoder\n",
        "\n",
        "def df_retain(df, columns, debug=False):\n",
        "  \"\"\"\n",
        "  Given a DataFrame and a list of column names, retain only the listed columns.\n",
        "  Returns a dataframe with all but the listed columns removed.\n",
        "  \"\"\"\n",
        "  if (df is None):\n",
        "    return None\n",
        "\n",
        "  drop_cols = []\n",
        "  for col in df.columns:\n",
        "    if (col not in columns):\n",
        "      drop_cols.append(col)\n",
        "\n",
        "  if (debug):\n",
        "    print(f'Dropping columns: {drop_cols}')\n",
        "\n",
        "  return df.drop(columns=drop_cols)\n",
        "\n",
        "def create_timeindexed_df(start_date, end_date, freq='1M'):\n",
        "  \"\"\"\n",
        "  Create an empty DataFrame with index set up with dates in a regular pattern\n",
        "  for the currently set start/end dates and given frequency.\n",
        "  See https://pandas.pydata.org/docs/user_guide/timeseries.html#timeseries-offset-aliases\n",
        "  for the full frequency specification.\n",
        "  Default creates an index point at every first day of the month in the given range.\n",
        "  \"\"\"\n",
        "  if (not start_date or not end_date):\n",
        "    raise AssertionError('Time range required')\n",
        "\n",
        "  # See if we need an offset\n",
        "  offset = Day(0)  # Days do not, unless you're looking to back off Time units to midnight\n",
        "  if (freq[-1] == 'M'):\n",
        "    offset = MonthBegin(1)\n",
        "  elif (freq[-1] == 'Y'):\n",
        "    offset = YearBegin(1)\n",
        "\n",
        "  # Generate index\n",
        "  dates = pd.date_range(start_date, end_date, freq=freq) - offset\n",
        "\n",
        "  # Create empty df\n",
        "  return pd.DataFrame(index=dates)\n",
        "\n",
        "def clean_df(df, purge_suffixes=[]):\n",
        "  \"\"\"\n",
        "  Perform following on the given df:\n",
        "  * drop any column with a name ending in a given purge_suffix\n",
        "  * remove surrounding parands from any column name\n",
        "  * rename columns ending in \", mean\" to \"-Mean\"\n",
        "  \"\"\"\n",
        "  drop_list = []\n",
        "  tuple_list = {}\n",
        "\n",
        "  for col in df.columns:\n",
        "    if (isinstance(col, tuple)):\n",
        "      # rename tuple to just first entry\n",
        "      tuple_list[col] = col[0]\n",
        "    else:\n",
        "      for s in purge_suffixes:\n",
        "        if (col.endswith(s)):\n",
        "          drop_list.append(col)\n",
        "          break\n",
        "\n",
        "  # Drop columns w/ suffixes from list\n",
        "  df.drop(columns=drop_list, inplace=True)\n",
        "\n",
        "  # Rename mean cols\n",
        "  #for col in df.columns:\n",
        "  #  if (\", mean\" in col):\n",
        "  #    mean_list[col] = f'{col[:-6]}-Mean'\n",
        "\n",
        "  # Rename tuples\n",
        "  df.rename(columns=tuple_list, inplace=True)\n",
        "  return df"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "**Unit Tests**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "tKh7gc5XL5Gu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PU_UNIT_TEST = False"
      ],
      "metadata": {
        "id": "b2GZVFUp2GvR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unit Testing\n",
        "if PU_UNIT_TEST:\n",
        "  def get_test_df():\n",
        "    df = pd.DataFrame({'angles': [0, 3, 4],\n",
        "                      'degrees': [360.32, 180.31, 360.114],\n",
        "                      'code':['A','B','C']},\n",
        "                      index=['circle', 'triangle', 'rectangle'])\n",
        "    print(f'DataFrame: \\n{df}')\n",
        "    return df\n",
        "\n",
        "  print('--------------------------------------------')\n",
        "  print('Case 1: get_df_types()')\n",
        "  df = get_test_df()\n",
        "\n",
        "  # Determine data types in given columns\n",
        "  floats,ints,strings,other = get_df_types(df, True)\n",
        "\n",
        "  numerics = set(floats).union(set(ints))\n",
        "  alphas = set(strings).union(set(other))\n",
        "\n",
        "  print(f'Numeric cols: {numerics}')\n",
        "  print(f'Alpha cols: {alphas}')\n",
        "\n",
        "  print('--------------------------------------------')\n",
        "  print('Case 2: df_to_arrays() - alpha target')\n",
        "  df = get_test_df()\n",
        "\n",
        "  X, y, enc = df_to_arrays(df, 'code', debug=True)\n",
        "  print(f'X: {X}')\n",
        "  print(f'y: {y}')\n",
        "  print(f'enc: {enc}')\n",
        "\n",
        "  print('--------------------------------------------')\n",
        "  print('Case 3: df_to_arrays() - alpha col, numer. target')\n",
        "  df = get_test_df()\n",
        "\n",
        "  X, y, enc = df_to_arrays(df, 'angles', debug=True)\n",
        "  print(f'X: {X}')\n",
        "  print(f'y: {y}')\n",
        "  print(f'enc: {enc}')\n",
        "\n",
        "  print('--------------------------------------------')\n",
        "  print('Case 4: df_retain() - retain only \"angles\"')\n",
        "  df = get_test_df()\n",
        "\n",
        "  df = df_retain(df, 'angles', debug=True)\n",
        "  print(f'df: {df.columns}')\n",
        "\n"
      ],
      "metadata": {
        "id": "5lPOL4AQT8SZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sre_constants import error\n",
        "if PU_UNIT_TEST:\n",
        "  import pandas as pd\n",
        "  from datetime import datetime as dt\n",
        "  import datetime\n",
        "\n",
        "  START_DATE =  pd.to_datetime(dt.fromisoformat('1999-01-01'))\n",
        "  # Stop including data after this date\n",
        "  END_DATE = pd.to_datetime(dt.fromisoformat('2002-12-31'))\n",
        "\n",
        "  print('--------------------------------------------')\n",
        "  print('Case 5a: create_timeindexed_df() - no date')\n",
        "  try:\n",
        "    # Error expected\n",
        "    df = create_timeindexed_df(START_DATE, None, freq='1M')\n",
        "  except AssertionError as e:\n",
        "    print (f'Caught expected error: {e}')\n",
        "\n",
        "  print('--------------------------------------------')\n",
        "  print('Case 5b: create_timeindexed_df() - 1M')\n",
        "  df = create_timeindexed_df(START_DATE, END_DATE, freq='1M')\n",
        "  print(df.index)\n",
        "\n",
        "  print('--------------------------------------------')\n",
        "  print('Case 5c: create_timeindexed_df() - 1D')\n",
        "  df = create_timeindexed_df(START_DATE, END_DATE, freq='1D')\n",
        "  print(df.index)\n",
        "\n",
        "  print('--------------------------------------------')\n",
        "  print('Case 5c: create_timeindexed_df() - 1Y')\n",
        "  df = create_timeindexed_df(START_DATE, END_DATE, freq='1Y')\n",
        "  print(df.index)\n"
      ],
      "metadata": {
        "id": "HyZo1tavH6Zd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if PU_UNIT_TEST:\n",
        "  print('--------------------------------------------')\n",
        "  print('Case 6: () - ')\n",
        "  df = create_timeindexed_df(START_DATE, END_DATE, freq='1M')\n",
        "  df['date'] = df.index\n",
        "  print(df.columns)\n",
        "  print(df.head())\n",
        "  df['year'] = df['date'].apply(lambda x: x.year)\n",
        "  df['month'] = df['date'].apply(lambda x: f'{x.month:02}')"
      ],
      "metadata": {
        "id": "HdQXjK5243cm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if PU_UNIT_TEST:\n",
        "  df = pd.DataFrame({'days': ['Mon','Tues','Wed','Thurs','Fri'],\n",
        "                   ('vals', 'mean'): [1, 2, 3, 4, 5],\n",
        "                     'valdf':range(5)},\n",
        "                  index=range(5))\n",
        "  print(df)\n",
        "  df = clean_df(df, purge_suffixes=['df'])\n",
        "  print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pBYdpBjusXn0",
        "outputId": "d608f2d5-73ea-437f-a038-e5220c9f1c4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    days  (vals, mean)  valdf\n",
            "0    Mon             1      0\n",
            "1   Tues             2      1\n",
            "2    Wed             3      2\n",
            "3  Thurs             4      3\n",
            "4    Fri             5      4\n",
            "    days  vals\n",
            "0    Mon     1\n",
            "1   Tues     2\n",
            "2    Wed     3\n",
            "3  Thurs     4\n",
            "4    Fri     5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T89X1kjHs88o"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Data606 - Capstone Project\n",
        "```\n",
        "Group H\n",
        "Malav Patel, Kent Butler\n",
        "Prof. Unal Sokaglu\n",
        "```"
      ],
      "metadata": {
        "id": "om0kO_8Wjrdp"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wi36j3siBTJw"
      },
      "source": [
        "This project is about performing time-series analysis on climate data analysis data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Research"
      ],
      "metadata": {
        "id": "ITMtlPsgRtyw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### References"
      ],
      "metadata": {
        "id": "wPKxbg_slFF8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some explanations of earth sciences statistics:\n",
        "https://pjbartlein.github.io/REarthSysSci/ltms-and-anomalies.html\n",
        "\n",
        "NOAA PSL NCEP-NCAR datasets:  https://psl.noaa.gov/data/gridded/data.ncep.reanalysis.html\n",
        "\n",
        "NOAA PSL, other recognized data sources directory: https://psl.noaa.gov/data/help/othersources/\n",
        "\n",
        "Global environmental policy timeline, https://www.boell.de/en/2022/05/28/international-environmental-policy-timeline\n",
        "\n",
        "OECD convergence of policy, climate,and economy: https://www.oecd.org/\n",
        "\n",
        "NASA climate time machine: https://climate.nasa.gov/interactives/climate-time-machine"
      ],
      "metadata": {
        "id": "PoW6sjUCRvt_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Factoids"
      ],
      "metadata": {
        "id": "o8PeuAHRlHPh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* All of the plastic waste produced in the world in 2019 alone weighs as much as 35,000 Eiffel Towers â€“ 353 million tons  - [*Organization for Economic Cooperation and Development (OECD)*](https://www.boell.de/en/2022/05/28/international-environmental-policy-timeline)\n",
        "\n"
      ],
      "metadata": {
        "id": "WYSxM-qHlJck"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hv3TRSF9pQXW"
      },
      "source": [
        "## Application Parameters\n",
        "\n",
        "Note: algorithm tuning is done with declaration of the model."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from datetime import datetime as dt\n",
        "import datetime"
      ],
      "metadata": {
        "id": "WWu_MYu0lkNC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns; sns.set()\n",
        "plt.rcParams[\"figure.figsize\"] = (10,6)\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "plt.style.use('seaborn')\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "fzbBsSdnMPuK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-FHrtmWM1HKt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2cc9bf4-bdf2-4ce1-9464-35d604686920"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "--Xazpo9sqfa"
      },
      "outputs": [],
      "source": [
        "debug = False\n",
        "\n",
        "DRIVE_PATH = \"/content/drive/MyDrive/data606\"\n",
        "\n",
        "# Set the location of this script in GDrive\n",
        "SCRIPT_PATH = DRIVE_PATH + \"/src/\"\n",
        "\n",
        "# Root Path of the data on the cloud drive\n",
        "DATA_ROOT = DRIVE_PATH + \"/data/\"\n",
        "\n",
        "# Location of logged output prediction data\n",
        "LOG_PATH = DATA_ROOT + \"/preds/\"\n",
        "\n",
        "# Journal file\n",
        "JOURNAL_LOG = SCRIPT_PATH + \"cv-results.csv\"\n",
        "\n",
        "# Start including data from this date\n",
        "START_DATE =  pd.to_datetime(dt.fromisoformat('1950-01-01'))\n",
        "# Stop including data after this date\n",
        "END_DATE = pd.to_datetime(dt.fromisoformat('2015-12-01'))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd $SCRIPT_PATH"
      ],
      "metadata": {
        "id": "0966NfEwk60W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52b9cb30-dfea-42f6-c39d-52a1420c0dfc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/data606/src\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load util class\n",
        "%run -i \"./ProjectUtil.ipynb\""
      ],
      "metadata": {
        "id": "ctfJaN2RWFsG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load util class\n",
        "%run -i \"./ModelExecutor.ipynb\""
      ],
      "metadata": {
        "id": "F49q7X3esOwM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fe2775a-6c0f-426c-935e-53023ea0e459"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/data606/src\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model class\n",
        "%run -i \"./Model_LSTMv2.ipynb\""
      ],
      "metadata": {
        "id": "tTM2a-8zWv5l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load util class\n",
        "#%run -i \"./WindowGenerator.ipynb\""
      ],
      "metadata": {
        "id": "xSiMwBNa66qM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dataset Definitions**"
      ],
      "metadata": {
        "id": "wwCzMksgGfi6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Label to predict\n",
        "TARGET_LABEL = 'landSeaAvgTemp'\n",
        "\n",
        "# Base dataset\n",
        "TEMP_DATA = {'filename':'GlobalTemperatures.csv',\n",
        "             'feature_map':{'LandAndOceanAverageTemperature':'landSeaAvgTemp'},\n",
        "             'date_col':'dt'}\n",
        "\n",
        "#TEMP_DATA = {'filename':'GlobalTemperatures.csv',\n",
        "#              'feature_map':{'LandAverageTemperature':'landAvgTemp',\t'LandMaxTemperature':'landMaxTemp',\t'LandMinTemperature':'landMinTemp',\t'LandAndOceanAverageTemperature':'landSeaAvgTemp'},\n",
        "#               'date_col':'dt'}\n",
        "\n",
        "# Datasets\n",
        "CO2_DATA = {'filename':\"atmospheric-co2.csv\",\n",
        "            'feature_map':{'Carbon Dioxide (ppm)':'co2', 'Seasonally Adjusted CO2 (ppm)':'co2_seas'},\n",
        "            'date_map':{'Year':'year','Month':'month'}}\n",
        "\n",
        "SEAICE_DATA = {'filename':\"seaice.csv\",\n",
        "               'feature_map':{'     Extent':'ice_extent','    Missing':'ice_missing'},\n",
        "               'date_map':{' Month':'month','Year':'year',' Day':'day'}}\n",
        "\n",
        "WEATHER_DATA = {'filename':\"finalDatasetWithRain.csv\",\n",
        "                'feature_map':{'air_x':'air_x','air_y':'air_y','uwnd':'uwnd'},\n",
        "                'date_col':'time'}\n",
        "\n",
        "VOLCANO_DATA = {'filename':'eruptions-conditioned.csv',\n",
        "                'feature_map':{'vei':'volcanic_idx'},\n",
        "                'date_map':{'start_year':'year','start_month':'month'}}\n",
        "\n",
        "FOREST_DATA = {'filename':'WorldForestCover.csv',\n",
        "               'feature_map':{'PctCover':'pct_forest_cover'},\n",
        "               'date_map':{'Year':'year'}}\n",
        "\n",
        "SUNSPOT_DATA = {'filename':'sunspotnumber.csv',\n",
        "               'feature_map':{'suns_spot_number':'sunspot_num'},\n",
        "               'date_map':{'year':'year'}}\n",
        "\n",
        "POLICY_DATA = {'filename':'GlobalEnvPolicies.csv',\n",
        "               'feature_map':{'EventRating':'policy_rate'},\n",
        "               'date_col':'date'}\n",
        "\n",
        "#GHG_DATA = {'filename':'greenhouse_gas_inventory_data.csv',\n",
        "#            'feature_map':{''},\n",
        "#            'date_map':{'Year':'year'}}\n"
      ],
      "metadata": {
        "id": "Ajo1I7UQGfDN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hyperparams**"
      ],
      "metadata": {
        "id": "uGwYIb9eO3q6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# History lookback in network\n",
        "INPUT_WINDOW = 30\n",
        "# How far forward to predict\n",
        "LABEL_WINDOW = 1\n",
        "# Ratio of test data to train data - used for split\n",
        "TEST_RATIO = 0.2\n",
        "# 0..1 percent of data to use as validation\n",
        "VALIDATION_RATIO = 0.1\n",
        "# Num epochs\n",
        "NUM_EPOCHS = 300\n",
        "# Model to use\n",
        "MODEL_NAME = \"LSTMv2\"\n",
        "\n",
        "ALL_DATASETS = [[CO2_DATA],\n",
        "  [CO2_DATA,FOREST_DATA],\n",
        "  [CO2_DATA,SEAICE_DATA],\n",
        "  [CO2_DATA,POLICY_DATA],\n",
        "  [CO2_DATA,SEAICE_DATA,POLICY_DATA],\n",
        "  [CO2_DATA,SEAICE_DATA,WEATHER_DATA],\n",
        "  [CO2_DATA,SEAICE_DATA,WEATHER_DATA,FOREST_DATA],\n",
        "  [CO2_DATA,SEAICE_DATA,WEATHER_DATA,FOREST_DATA,VOLCANO_DATA],\n",
        "  [CO2_DATA,SEAICE_DATA,WEATHER_DATA,FOREST_DATA,VOLCANO_DATA,SUNSPOT_DATA],\n",
        "  [CO2_DATA,VOLCANO_DATA],\n",
        "  [CO2_DATA,VOLCANO_DATA,FOREST_DATA],\n",
        "  [CO2_DATA,VOLCANO_DATA,FOREST_DATA,SEAICE_DATA],\n",
        "  [CO2_DATA,VOLCANO_DATA,FOREST_DATA,SEAICE_DATA,SUNSPOT_DATA],\n",
        "  [CO2_DATA,FOREST_DATA],\n",
        "  [CO2_DATA,FOREST_DATA,SEAICE_DATA],\n",
        "  [CO2_DATA,FOREST_DATA,SEAICE_DATA,SUNSPOT_DATA],\n",
        "  [VOLCANO_DATA],\n",
        "  [VOLCANO_DATA,FOREST_DATA],\n",
        "  [VOLCANO_DATA,POLICY_DATA],\n",
        "  [VOLCANO_DATA,FOREST_DATA,SUNSPOT_DATA],\n",
        "  [VOLCANO_DATA,FOREST_DATA,SUNSPOT_DATA,POLICY_DATA],\n",
        "  [VOLCANO_DATA,FOREST_DATA,SUNSPOT_DATA,POLICY_DATA,SEAICE_DATA],\n",
        "  [FOREST_DATA],\n",
        "  [FOREST_DATA,POLICY_DATA],\n",
        "  [SEAICE_DATA],\n",
        "  [SEAICE_DATA,FOREST_DATA],\n",
        "  [SEAICE_DATA,POLICY_DATA],\n",
        "  [SEAICE_DATA,FOREST_DATA,VOLCANO_DATA],\n",
        "  [SEAICE_DATA,FOREST_DATA,VOLCANO_DATA,POLICY_DATA]\n",
        "]"
      ],
      "metadata": {
        "id": "TQCZqROdOrls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ALL_DATASETS=[ALL_DATASETS[1]]"
      ],
      "metadata": {
        "id": "d5qswqjMU6Hd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Execute Trainer"
      ],
      "metadata": {
        "id": "4-fpkdHNb595"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Declare a merger compatible with our source data and our target dataset we want to merge into\n",
        "#  (self, data_path, journal_log, start_date, end_date, input_window, label_window, test_ratio, val_ratio, num_epochs, target_label, model_name, debug=False):\n",
        "\n",
        "for i,ds_list in enumerate(ALL_DATASETS):\n",
        "\n",
        "  fnames = [ds['filename'] for ds in ds_list]\n",
        "  print(f'============================ Executing {i} ===================================\\n{fnames}')\n",
        "\n",
        "  # re-construct the model exec b/c it contains some state\n",
        "  exec = ModelExecutor(data_path=DATA_ROOT, log_path=LOG_PATH, journal_log=JOURNAL_LOG, start_date=START_DATE, end_date=END_DATE,\n",
        "                      input_window=INPUT_WINDOW, label_window=LABEL_WINDOW, test_ratio=TEST_RATIO, val_ratio=VALIDATION_RATIO,\n",
        "                      num_epochs=NUM_EPOCHS, target_label=TARGET_LABEL, model_name=MODEL_NAME, debug=True)\n",
        "\n",
        "  exec.load_initial_dataset(TEMP_DATA['filename'], TEMP_DATA['feature_map'], date_map=None, date_col=TEMP_DATA['date_col'])\n",
        "\n",
        "  exec.load_datasets(ds_list)\n",
        "\n",
        "  #exec.print_correlations()\n",
        "\n",
        "  exec.process()\n",
        "\n",
        "  print(f'=========================== Completed {i} ===================================')\n"
      ],
      "metadata": {
        "id": "eKE70OoByrtX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
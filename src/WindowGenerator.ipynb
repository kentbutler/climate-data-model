{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##WindowGenerator\n",
        "\n",
        "Windowing calculator - adapted from TensorFlow tutorial at:\n",
        "\n",
        "https://www.tensorflow.org/tutorials/structured_data/time_series\n",
        "\n",
        "Defines a windowing tool which can be applied to any given 2D DataFrame with the configured label column(s). Supports single or multi-label targets.\n",
        "\n",
        "Transforms input into a time-stepped dataset prepared for supervised learning analysis.\n",
        "\n",
        "Outputs a 3D dataset:  (batch, time, features)\n",
        "\n",
        "where `time` is data per timestep, i.e. if training on a 1-year monthly lookback, then the `time` dimension should be 12."
      ],
      "metadata": {
        "id": "x_Qe94Mz6aH6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XsVLnqDP6Y5t"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.data import Dataset\n",
        "\n",
        "class TfWindowGenerator():\n",
        "  \"\"\"\n",
        "  Construct a TfWindowGenerator that operates with the following params:\n",
        "  * input_width - the number of time steps to use as the input window\n",
        "  * label_width - the number of time steps to use as output\n",
        "  * shift - offset that places the output prediction along the window; equal to\n",
        "  or greater than the label_width\n",
        "  * label_columns - name(s) of the label columns\n",
        "  \"\"\"\n",
        "  def __init__(self, input_width, label_width, shift=1, debug=False):\n",
        "    # GUARDs\n",
        "    #if shift < label_width:\n",
        "    #  raise AssertionError('Shift must contain label_width (must be <=)')\n",
        "\n",
        "    self.debug = debug\n",
        "\n",
        "    # Assess window parameters\n",
        "    self.input_width = input_width\n",
        "    self.label_width = label_width\n",
        "    self.shift = shift\n",
        "\n",
        "    # Total number of data rows to extract per window/frame\n",
        "    self.total_window_size = input_width + shift\n",
        "    # Index within a window/frame to look for the label(s)\n",
        "    self.label_start = self.total_window_size - self.label_width\n",
        "\n",
        "    # Build slicers which will operate on stacked time-frames\n",
        "    self.input_slice = slice(0, input_width)\n",
        "    self.labels_slice = slice(self.label_start, self.total_window_size)\n",
        "\n",
        "    # Indexes into window/frame\n",
        "    self.input_indices = np.arange(self.total_window_size)[self.input_slice]\n",
        "    self.label_indices = np.arange(self.total_window_size)[self.labels_slice]\n",
        "\n",
        "    if (debug):\n",
        "      print('\\n'.join([\n",
        "         f'input_slice: {self.input_slice}',\n",
        "         f'labels_slice: {self.labels_slice}',\n",
        "         f'input_indices: {self.input_indices}',\n",
        "         f'label_indices: {self.label_indices}'\n",
        "      ]))\n",
        "\n",
        "  def __repr__(self):\n",
        "    \"\"\"\n",
        "    Print object stats.\n",
        "    \"\"\"\n",
        "    return '\\n'.join([\n",
        "        f'Total window size: {self.total_window_size}',\n",
        "        f'Input indices: {self.input_indices}',\n",
        "        f'Label indices: {self.label_indices}'])\n",
        "\n",
        "\n",
        "  def generate(self, features, label_cols):\n",
        "    \"\"\"\n",
        "    Probably deprecated??   Use get_windowed() instead.\n",
        "\n",
        "    Given a feature set of normalized values, create a windowed stack of\n",
        "    inputs with output labels split out.\n",
        "\n",
        "    Returns (inputs, outputs).\n",
        "    \"\"\"\n",
        "    # Restack data into frames the size of our total window\n",
        "    # NOTE this currently retains all target columns\n",
        "    WINDOW_SIZE = self.total_window_size\n",
        "    LAST_WINDOW_START = features.shape[0]-self.total_window_size\n",
        "    NUM_FRAMES = LAST_WINDOW_START+1\n",
        "\n",
        "    frames = []\n",
        "    #   Apply for each row\n",
        "    for r in range(0, NUM_FRAMES):\n",
        "      frames.append(features[r:r+WINDOW_SIZE])\n",
        "\n",
        "    frames = np.array(frames)\n",
        "\n",
        "    if (self.debug):\n",
        "      print (f'Frames: {frames.shape}')\n",
        "      print (f'First frame: {frames[0]}')\n",
        "      print (f'Last frame: {frames[-1]}')\n",
        "\n",
        "    #inputs = features[self.input_slice, :]\n",
        "\n",
        "    # Extract a tensor of stack of input frames\n",
        "    #   NOTE This still includes labels\n",
        "    if (self.debug):\n",
        "      print(f'Slicing inputs with: {self.input_slice}')\n",
        "    inputs = frames[:, self.input_slice]\n",
        "\n",
        "    # Extract a list of label frames\n",
        "    #TODO how do I subselect the right y column(s) out of this?\n",
        "    if (self.debug):\n",
        "      print(f'Slicing labels with: {self.labels_slice}')\n",
        "    labels = frames[:, self.labels_slice]\n",
        "    #ret_labels = labels\n",
        "\n",
        "    if (self.debug):\n",
        "      print(f'--- Inputs ---\\n{inputs.shape}')\n",
        "      print(f'--- Labels ---\\n{labels.shape}')\n",
        "\n",
        "    # Define all column indices\n",
        "    if (self.debug):\n",
        "      print(f'enumerating columns: {features.columns}')\n",
        "    column_indices = {name: i for i, name in enumerate(features.columns)}\n",
        "    #label_columns_indices = {name: i for i, name in enumerate(self.label_columns)}\n",
        "    if (self.debug):\n",
        "      print(f'Column indices: {column_indices}')\n",
        "\n",
        "    # Create tf tensor from inputs\n",
        "    #for name in self.label_columns:\n",
        "    #  print(f'Col indices: {name}:: {column_indices[name]}')\n",
        "    #  print(f'labels: {name}::\\n {labels[:,:,column_indices[name]]}')\n",
        "\n",
        "    #only_labels = [labels[:,:,column_indices[name]] for name in self.label_columns]\n",
        "    #only_labels = np.array(only_labels)\n",
        "    #print(f'only_labels.shape: {only_labels.shape}')\n",
        "    #print(only_labels)\n",
        "\n",
        "    # Locate the label columns, for extraction\n",
        "    label_indices = [column_indices[name] for name in label_cols]\n",
        "    # Extract labels! Keeping rest of the shape\n",
        "    labels = np.take(labels, label_indices, axis=2)\n",
        "\n",
        "    #labels = tf.stack(only_labels)\n",
        "\n",
        "    #arr = [labels[:,:,column_indices[name]] for name in self.label_columns]\n",
        "    #arr = np.array(arr)\n",
        "    #print(f'arr.shape: {arr.shape}')\n",
        "\n",
        "    #if (self.debug):\n",
        "    #  print('\\n'.join([\n",
        "    #      'Returned shapes, before re-shape::',\n",
        "    #      f'\\tInputs: {inputs.shape}',\n",
        "    #      f'\\tLabels: {labels.shape}'\n",
        "    #  ]))\n",
        "\n",
        "    # Slicing doesn't preserve static shape information, so set the shapes\n",
        "    # manually. This way the `tf.data.Datasets` are easier to inspect.\n",
        "    #inputs.reshape([-1, self.input_width, None])\n",
        "    #labels.reshape([-1, self.label_width])\n",
        "    #tf.reshape(labels, (NUM_FRAMES, -1, self.label_width))\n",
        "\n",
        "    if (self.debug):\n",
        "      print('\\n'.join([\n",
        "          'Returned shapes::',\n",
        "          f'\\tInputs: {inputs.shape}',\n",
        "          f'\\tLabels: {labels.shape}'\n",
        "      ]))\n",
        "\n",
        "    # Store the last dataset\n",
        "    self.inputs = inputs\n",
        "    self.labels = labels\n",
        "\n",
        "    return inputs, labels\n",
        "\n",
        "  def get_windowed(self, df, label_cols):\n",
        "    \"\"\"\n",
        "    Replaces generate.\n",
        "    \"\"\"\n",
        "    if (df is None):\n",
        "      raise AssertionError('Dataframe required')\n",
        "\n",
        "    df_labels = df[label_cols]\n",
        "    df_features = df.drop(columns=label_cols)\n",
        "\n",
        "    print(f'## Labels: {df_labels.shape}')\n",
        "    print(f'## Features: {df_features.shape}')\n",
        "\n",
        "    # Slice labels to begin after first input window\n",
        "    df_labels = df_labels.iloc[self.input_width:]\n",
        "\n",
        "    print(f'## Labels: {df_labels.shape}')\n",
        "\n",
        "    inputs = tf.data.Dataset.from_tensor_slices(df_features)\n",
        "    labels = tf.data.Dataset.from_tensor_slices(df_labels)\n",
        "\n",
        "    return inputs, labels\n",
        "\n",
        "  def get_dataset(self, df, label_cols):\n",
        "    \"\"\"\n",
        "    Create a TF dataset from the given df.\n",
        "    Example:  train_ds = get_dataset(train_df)\n",
        "\n",
        "    For label_cols of size one, will return a dataset batching a 2D input\n",
        "    and a 1D list of labels.\n",
        "\n",
        "    For label_cols of size greater than one, will return a dataset batching a 2D input\n",
        "    and a dataset batching a 2D set of labels.\n",
        "    \"\"\"\n",
        "    if (df is None):\n",
        "      raise AssertionError('Dataframe required')\n",
        "\n",
        "    df_labels = df[label_cols]\n",
        "    df_features = df.drop(columns=label_cols)\n",
        "\n",
        "    print(f'## Labels: {df_labels.shape}')\n",
        "    print(f'## Features: {df_features.shape}')\n",
        "\n",
        "    # Slice labels to begin after first input window\n",
        "    df_labels = df_labels.iloc[self.input_width:]\n",
        "\n",
        "    print(f'## Labels: {df_labels.shape}')\n",
        "\n",
        "    # Simple case: single output\n",
        "    if (self.label_width == 1):\n",
        "      ds = tf.keras.utils.timeseries_dataset_from_array(\n",
        "          data=df_features,\n",
        "          targets=df_labels[label_cols].values,\n",
        "          sequence_length=self.input_width)\n",
        "    else:\n",
        "      # More than a single label\n",
        "      features_dataset = Dataset.from_tensor_slices(df_features)\n",
        "      labels_dataset = Dataset.from_tensor_slices(df_labels)\n",
        "      ds = Dataset.zip((features_dataset, labels_dataset))\n",
        "\n",
        "    return ds\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "**Unit testing**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "hhpwZrhJ1N9y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "WG_UNIT_TEST = True"
      ],
      "metadata": {
        "id": "Ebu7GvfzMcLe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if WG_UNIT_TEST:\n",
        "  from datetime import datetime as dt\n",
        "  import datetime\n",
        "  import pandas as pd\n",
        "\n",
        "  a = []\n",
        "  b = []\n",
        "  c = []\n",
        "  idx = []\n",
        "  NUM_PTS = 11\n",
        "  date_start = dt.strptime(\"1/1/11\", \"%m/%d/%y\")\n",
        "\n",
        "  for t in range(1,NUM_PTS+1):\n",
        "    # just append some letter to t\n",
        "    a.append(chr(96+t))\n",
        "    b.append(t)\n",
        "    c.append(t * 0.125)\n",
        "    idx.append(date_start + datetime.timedelta(days=t))\n",
        "\n",
        "  df = pd.DataFrame({'A':a,\n",
        "                    'B': b,\n",
        "                    'C':c},\n",
        "                  index=idx)\n",
        "\n",
        "  #print (df)\n",
        "\n",
        "  # Label encode our target vals - going to use plain old py char vals\n",
        "  df['A'] = df['A'].apply(lambda x: ord(x))\n",
        "\n",
        "  # Scale values\n",
        "  #df_mean = df.mean()\n",
        "  #df_std = df.std()\n",
        "  #df = (df - df_mean) / df_std\n",
        "\n",
        "  print (df)\n",
        "  print(f'Shape: {df.shape}')\n",
        "\n",
        "  # Case 1: FAIL: Create failed windower - raises AssertionError\n",
        "  #win = TfWindowGenerator(input_width=4, label_width=1, shift=1)\n",
        "\n",
        "  # Case 2: Create windower for single label timeframe, single label column\n",
        "  IN_WIDTH=4\n",
        "  LAB_WIDTH=1\n",
        "  SHIFT=1\n",
        "  LAB_COLS=['A']\n",
        "  win = TfWindowGenerator(input_width=IN_WIDTH, label_width=LAB_WIDTH, shift=SHIFT, debug=True)\n",
        "  print('--- Case 2 ------\\n', f'input_width={IN_WIDTH}, label_width={LAB_WIDTH}, shift={SHIFT}, label_columns={LAB_COLS}')\n",
        "  print(win)\n",
        "\n",
        "  # Split X/y\n",
        "  inputs, labels = win.generate(df, LAB_COLS)\n",
        "\n",
        "  print(f'Generated inputs: {inputs.shape} , labels: {labels.shape}')\n",
        "\n",
        "  # Case 3 Create dataset, single label column\n",
        "  IN_WIDTH=4\n",
        "  LAB_WIDTH=1\n",
        "  SHIFT=1\n",
        "  LAB_COLS=['A']\n",
        "  win = TfWindowGenerator(input_width=IN_WIDTH, label_width=LAB_WIDTH, shift=SHIFT, debug=True)\n",
        "  print('--- Case 3 ------\\n', f'input_width={IN_WIDTH}, label_width={LAB_WIDTH}, shift={SHIFT}, label_columns={LAB_COLS}')\n",
        "  print(win)\n",
        "\n",
        "  print('Making/iterating dataset...')\n",
        "  ds = win.get_dataset(df, LAB_COLS)\n",
        "  for batch in ds:\n",
        "    X, y = batch\n",
        "    print(f'-----X-----------\\n{X}')\n",
        "    print(f'-----y-----------\\n{y}')\n",
        "    break\n",
        "\n",
        "\n",
        "  # Case 4 Create dataset, multi label columns\n",
        "  IN_WIDTH=4\n",
        "  LAB_WIDTH=2\n",
        "  SHIFT=1\n",
        "  LAB_COLS=['A','B']\n",
        "  win = TfWindowGenerator(input_width=IN_WIDTH, label_width=LAB_WIDTH, shift=SHIFT, debug=True)\n",
        "  print('--- Case 4 ------\\n', f'input_width={IN_WIDTH}, label_width={LAB_WIDTH}, shift={SHIFT}, label_columns={LAB_COLS}')\n",
        "  print(win)\n",
        "\n",
        "  print('Making/iterating dataset...')\n",
        "  ds = win.get_dataset(df, LAB_COLS)\n",
        "  for batch in ds:\n",
        "    X, y = batch\n",
        "    print(f'-----X-----------\\n{X}')\n",
        "    print(f'-----y-----------\\n{y}')\n",
        "    break\n",
        "\n",
        "\n",
        "  # Case 5 Get windows input/outputs, multi label columns\n",
        "  IN_WIDTH=4\n",
        "  LAB_WIDTH=2\n",
        "  SHIFT=1\n",
        "  LAB_COLS=['A','B']\n",
        "  win = TfWindowGenerator(input_width=IN_WIDTH, label_width=LAB_WIDTH, shift=SHIFT, debug=True)\n",
        "  print('--- Case 5 ------\\n', f'input_width={IN_WIDTH}, label_width={LAB_WIDTH}, shift={SHIFT}, label_columns={LAB_COLS}')\n",
        "  print(win)\n",
        "\n",
        "  print('Making/iterating dataset...')\n",
        "  ins,labs = win.get_windowed(df, LAB_COLS)\n",
        "  for batch in zip(ins,labs):\n",
        "    X, y = batch\n",
        "    print(f'-----X-----------\\n{X}')\n",
        "    print(f'-----y-----------\\n{y}')\n",
        "    break\n",
        "\n"
      ],
      "metadata": {
        "id": "l4iUUjY-rz4L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52ce2776-5456-4ed9-85bb-d9bcfd39cbe3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              A   B      C\n",
            "2011-01-02   97   1  0.125\n",
            "2011-01-03   98   2  0.250\n",
            "2011-01-04   99   3  0.375\n",
            "2011-01-05  100   4  0.500\n",
            "2011-01-06  101   5  0.625\n",
            "2011-01-07  102   6  0.750\n",
            "2011-01-08  103   7  0.875\n",
            "2011-01-09  104   8  1.000\n",
            "2011-01-10  105   9  1.125\n",
            "2011-01-11  106  10  1.250\n",
            "2011-01-12  107  11  1.375\n",
            "Shape: (11, 3)\n",
            "input_slice: slice(0, 4, None)\n",
            "labels_slice: slice(4, 5, None)\n",
            "input_indices: [0 1 2 3]\n",
            "label_indices: [4]\n",
            "--- Case 2 ------\n",
            " input_width=4, label_width=1, shift=1, label_columns=['A']\n",
            "Total window size: 5\n",
            "Input indices: [0 1 2 3]\n",
            "Label indices: [4]\n",
            "Frames: (7, 5, 3)\n",
            "First frame: [[ 97.      1.      0.125]\n",
            " [ 98.      2.      0.25 ]\n",
            " [ 99.      3.      0.375]\n",
            " [100.      4.      0.5  ]\n",
            " [101.      5.      0.625]]\n",
            "Last frame: [[103.      7.      0.875]\n",
            " [104.      8.      1.   ]\n",
            " [105.      9.      1.125]\n",
            " [106.     10.      1.25 ]\n",
            " [107.     11.      1.375]]\n",
            "Slicing inputs with: slice(0, 4, None)\n",
            "Slicing labels with: slice(4, 5, None)\n",
            "--- Inputs ---\n",
            "(7, 4, 3)\n",
            "--- Labels ---\n",
            "(7, 1, 3)\n",
            "enumerating columns: Index(['A', 'B', 'C'], dtype='object')\n",
            "Column indices: {'A': 0, 'B': 1, 'C': 2}\n",
            "Returned shapes::\n",
            "\tInputs: (7, 4, 3)\n",
            "\tLabels: (7, 1, 1)\n",
            "Generated inputs: (7, 4, 3) , labels: (7, 1, 1)\n",
            "input_slice: slice(0, 4, None)\n",
            "labels_slice: slice(4, 5, None)\n",
            "input_indices: [0 1 2 3]\n",
            "label_indices: [4]\n",
            "--- Case 3 ------\n",
            " input_width=4, label_width=1, shift=1, label_columns=['A']\n",
            "Total window size: 5\n",
            "Input indices: [0 1 2 3]\n",
            "Label indices: [4]\n",
            "Making/iterating dataset...\n",
            "## Labels: (11, 1)\n",
            "## Features: (11, 2)\n",
            "## Labels: (7, 1)\n",
            "-----X-----------\n",
            "[[[ 1.     0.125]\n",
            "  [ 2.     0.25 ]\n",
            "  [ 3.     0.375]\n",
            "  [ 4.     0.5  ]]\n",
            "\n",
            " [[ 2.     0.25 ]\n",
            "  [ 3.     0.375]\n",
            "  [ 4.     0.5  ]\n",
            "  [ 5.     0.625]]\n",
            "\n",
            " [[ 3.     0.375]\n",
            "  [ 4.     0.5  ]\n",
            "  [ 5.     0.625]\n",
            "  [ 6.     0.75 ]]\n",
            "\n",
            " [[ 4.     0.5  ]\n",
            "  [ 5.     0.625]\n",
            "  [ 6.     0.75 ]\n",
            "  [ 7.     0.875]]\n",
            "\n",
            " [[ 5.     0.625]\n",
            "  [ 6.     0.75 ]\n",
            "  [ 7.     0.875]\n",
            "  [ 8.     1.   ]]\n",
            "\n",
            " [[ 6.     0.75 ]\n",
            "  [ 7.     0.875]\n",
            "  [ 8.     1.   ]\n",
            "  [ 9.     1.125]]\n",
            "\n",
            " [[ 7.     0.875]\n",
            "  [ 8.     1.   ]\n",
            "  [ 9.     1.125]\n",
            "  [10.     1.25 ]]]\n",
            "-----y-----------\n",
            "[[101]\n",
            " [102]\n",
            " [103]\n",
            " [104]\n",
            " [105]\n",
            " [106]\n",
            " [107]]\n",
            "input_slice: slice(0, 4, None)\n",
            "labels_slice: slice(3, 5, None)\n",
            "input_indices: [0 1 2 3]\n",
            "label_indices: [3 4]\n",
            "--- Case 4 ------\n",
            " input_width=4, label_width=2, shift=1, label_columns=['A', 'B']\n",
            "Total window size: 5\n",
            "Input indices: [0 1 2 3]\n",
            "Label indices: [3 4]\n",
            "Making/iterating dataset...\n",
            "## Labels: (11, 2)\n",
            "## Features: (11, 1)\n",
            "## Labels: (7, 2)\n",
            "-----X-----------\n",
            "[0.125]\n",
            "-----y-----------\n",
            "[101   5]\n",
            "input_slice: slice(0, 4, None)\n",
            "labels_slice: slice(3, 5, None)\n",
            "input_indices: [0 1 2 3]\n",
            "label_indices: [3 4]\n",
            "--- Case 5 ------\n",
            " input_width=4, label_width=2, shift=1, label_columns=['A', 'B']\n",
            "Total window size: 5\n",
            "Input indices: [0 1 2 3]\n",
            "Label indices: [3 4]\n",
            "Making/iterating dataset...\n",
            "## Labels: (11, 2)\n",
            "## Features: (11, 1)\n",
            "## Labels: (7, 2)\n",
            "-----X-----------\n",
            "[0.125]\n",
            "-----y-----------\n",
            "[101   5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tf.data.Dataset.range(7).window(3, shift=1,\n",
        "                                          drop_remainder=True)\n",
        "for window in dataset:\n",
        "  print(list(window.as_numpy_iterator()))"
      ],
      "metadata": {
        "id": "oLoyjorCizas",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6f74306-1652-42ae-d119-9a2e06a59359"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 1, 2]\n",
            "[1, 2, 3]\n",
            "[2, 3, 4]\n",
            "[3, 4, 5]\n",
            "[4, 5, 6]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AHAN2IZclaJB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}